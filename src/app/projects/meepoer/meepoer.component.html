<div class="text-container read">
  <article class="read-wrap">
    <h1
      style="
        animation: transitionIn 0.75s;
        font-size: 58px;
        display: flex;
        justify-content: center;
      "
    >
      <div>Meepoer</div>
    </h1>
    <div
      class="img-container"
      style="animation: transitionIn 1.5s; margin-top: 20px"
    >
      <img
        height="500vwh"
        width="1500vwh"
        src="https://hahafhahalpaca-1305808520.cos.ap-shanghai.myqcloud.com/meepoer-intro.png"
      />
    </div>
    <div data-aos="zoom-in-up">
      <h3 class="p-content">
        Meepoer is an AI powered social media posts generator. (Named after the
        infamous Dota2 Hero Meepo). Check out the repo here: 
        <br /> 
        <a href="https://github.com/TyroneHe-0926/MeepoerPublic"> 
          https://github.com/TyroneHe-0926/MeepoerPublic
        </a>
        <br />
        <br />
        Meepoer was inspired by some of the newer technologies I played around
        with during my previous work term. The idea was to utilize GPT-3 (which
        just came out at the time) to build a tool for sales and marketing.
        Which transitioned into building a social media post generator late on.
        <br />
        <br />
        Imagine that you just built a great product and now you want to advertise it
        on different social media platforms, instead of having someone create 10
        different social media accounts to showcase your product, Meepoer can do
        that for you within seconds.
        <br />
        <br />
        Here is a brief overview of Meepoer and what it can accomplish
      </h3>
    </div>
    <div class="img-container" data-aos="zoom-in-down">
      <img
        height="600vwh"
        width="1700vwh"
        src="https://hahafhahalpaca-1305808520.cos.ap-shanghai.myqcloud.com/meepoer-feature.png"
      />
    </div>
    <div data-aos="zoom-in-up">
      <h3 class="p-content">
        Meepoer currenly supports Instagram, Twitter, Reddit, and Facebook.
        Besides generating content social media, it could also help writing
        Youtube captions, blogs, emails, etc.
      </h3>
    </div>
  </article>
</div>

<div
  class="text-container read"
  style="background-color: #a2978f; margin-top: 30px"
  data-aos="zoom-in-up"
>
  <article class="read-wrap" style="margin-top: 30px">
    <h3 class="p-content" data-aos="zoom-in-up">
      Now, we are gonna dive deep into how Meepoer works and what the generation
      process look like. The overall generation process follows:
      <br />
      <br />
    </h3>
    <div class="img-container" data-aos="zoom-in-down">
      <img height="700vh" width="1700vw"
      src="https://hahafhahalpaca-1305808520.cos.ap-shanghai.myqcloud.com/meepoer-process.png"/>
    </div>
    <h3 class="p-content" data-aos="zoom-in-up">
      Let's first, put it in simpler terms.
      To generate a post, we first need inputs from the user, they could be
      <li>
        &emsp; Some texts describing what the post is about
      </li>
      <li>
        &emsp; Images that depicts the type of content you want.
      </li>
      <li>
        &emsp; Post URLs from Twitter, Instagram, Reddit, etc.
      </li>
      We will then use the analyzed result to search similar images and captions within our database. After finding a few matches, we will generate captions and hashtags for the post, combined with the image(s), and your post is ready to go !
    </h3>
  </article>
</div>

<div class="text-container read" style="margin-top: 30px" data-aos="zoom-in-up">
  <article class="read-wrap">
    <h1 class="p-content" style="font-size: 30px">
      More on the technical side
    </h1>
    <br/>
    <h2 class="p-content">
      <b><strong>Text to Post Generation: </strong></b> 
    </h2>
    <h3 class="p-content" data-aos="zoom-in-up">
      Text to post generation has a relatively more straightforward implementation than post to post generation, so I wanna start by talking about text to post first.
      <br/>
      <br/>
      <ol>
        <li>Web scraping for data. Here we have scraped around 110G of Twitter posts, and 115G of Reddit posts, with their respective provided API. 
          <br/><br/>
          We have also scraped around 89G of Instagram posts using the open source repo at
          <a href="https://github.com/althonos/InstaLooter">https://github.com/althonos/InstaLooter</a>.
          <br/>
          I think it is worth mentioning that among all three platforms, we felt like Instagram's post quality tops the chart, we stopped at 89G only because our accounts are banned at that point.
        </li>
        <br/>
        <li>All scraped data will be uploaded to S3 in the format of a JSON file as well as its corresponding post images. The JSON file specified the property mapping to be automatically indexed into Elasticsearch, contains meta information such as <code>post_id</code>, <code>post_image_ar</code>, etc. and information like <code>hashtags</code>, <code>likes</code>, <code>text</code>, etc.
          <br/><br/>
          We also prioritized our scraping with BFS over DFS (scraping more hashtags/categories over scraping lots of post within a certain category). 
        </li>
        <br/>
        <li>The actual generation for TTP is rather simple. When user inputs a text prompt, we initiate a full text search task to our Redis Queue (will be explained later, just a task queue).
          <br/>
          After we matched the top posts stored in ES (target field is post's text), we could start finding more posts similar to those if the user wants.
          <br/><br/>
          After our ES hits return, it's time to do a bit of some prompt engineering (mainly how we communicate with GPT-3). We wanted GPT-3 to do some simple tasks such as summarizing and paraphrasing the post's content and description, in different ways, so that we can display a variety of contents to the users.
        </li>
        <br/>
        <li>We pretty much have everything we need for a generated post, we will now assemble the image, description, hashtags, text into an actual post and display to our front-end in the format of a post card. Watch a demo video of our TTP process here ↓
        </li>
      </ol>
      <div class="img-container" data-aos="zoom-in-down">
        <video width="1000" height="600" controls="controls" muted="true">
            <source src="https://s3.amazonaws.com/hahafhaha.com/Text-to-Post+Demo.mp4" type="video/mp4">
        </video>
     </div>
    </h3>
  </article>
</div>

<div
  class="text-container read"
  style="background-color: #a2978f; margin-top: 30px"
  data-aos="zoom-in-up"
>
  <article class="read-wrap" style="margin-top: 30px">
    <h2 class="p-content">
      <b><strong>Post to Post Generation: </strong></b> 
    </h2>
    <h3 class="p-content">
      Post to post generation has a more sophisticated generation process. While post to post might be slower, we found that embedding matching gave us an overall better results when generating similar posts based on image input.
      <br/><br/>
      <ol>
        <li>
          Assume we have already saved the images to S3 when collecting data from different social media platforms, besides indexing the result to ES, we also take the images and put into onto our task Redis Queue. 
          <br/><br/>
          Here, instead of setting up another cloud machine with a powerful GPU for inferencing, we reused one of our old Nvidia RTX 2060s and built a local machine at home. It listens for any incoming task on our task Redis Queue, and performs a place embedding extraction and a person embedding extraction on the current image, then indexes the extracted embedding to Milvus (a vector database).
          <br/><br/>
          We have tried the IVF_FLAT index and HNSW index for our Milvus collection, and decided to go with the HNSW index. The IVF_FLAT index is a on memory index, which uses the Inverted File Flat searching algorithm. It roughly performs a division on vector data and split them into <code>nlist</code> clusters, and then compares distances between the target input vector and the center of each cluster. When querying, we could set search through <code>nprobe</code> numbers of clusters. You can read more about the algorithm here at <a href="https://milvus.io/docs/index.md">the official Milvus documentation</a>.
          <br/><br/>
          The HNSW index is also an in memory index, which uses the HNSW (Hierarchical Navigable Small World Graph) algorithm. The HNSW algorithm is a graph based indexing algorithm, it builds a multi-layer navigation structure for an image according to certain rules. You can read more about the algorithm at <a href="https://zilliz.com/blog/hierarchical-navigable-small-worlds-HNSW">the Zilliz HNSW Blog</a> if interested. 
        </li>
        <br/>
        <li>
          Now that we have setted up our vector database, let's talk about how the query is performed. There isn't too much of a difference between an URL input and an image input. For URL inputs, all we did is parsing out all img tags and possible image URLs from the post's webpage, and use them as image input. 
          <br/><br/>
          When the user inputs an image, they could choose to either generate posts based on the image itself (here, we call it place embedding), or generate posts based on people in the image (here, we call it person embedding). For place embedding generations, we send a place extraction task to our GPU machine for inferencing, which then yields a 2048 dim vector. We first query the user's image vector and returns the top 10 results from Milvus. We then query these results and find the specific posts we saved in ES, and then assemble the posts with GPT-3 to display the generated posts.
          <br/><br/>
          For person embedding generations, we have to first locate people in the image, and then label the people appeared in the image with a number, then send a person extraction task to our GPU machine for inferencing (on the chosen person). It then yields a 256 dim vector, and the rest of the prodecure is similar to place embedding generation. Watch a demo video of our PTP process here ↓
        </li>
      </ol>
      <div class="img-container" data-aos="zoom-in-down">
        <video width="1000" height="600" controls="controls" muted="true">
            <source src="https://s3.amazonaws.com/hahafhaha.com/Post-to-Post+Demo.mp4" type="video/mp4">
        </video>
     </div>
     Here is a rough sketch of a Meepoer work flow diagram, which includes all components that I have discussed before (actually I think I forgot to add RQ). 
     <br/><br/>
     <div class="img-container" data-aos="zoom-in-down">
      <img width="1000" height="600" src="https://s3.amazonaws.com/hahafhaha.com/meepoer-diagram.jpeg"/>
   </div>
    </h3>
  </article>
</div>

<script>
  AOS.init();
</script>
